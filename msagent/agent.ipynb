{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating a multi-search agent tool to help students revise for exams, using a pdf or google search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create google search tool\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "os.environ['GOOGLE_API_KEY'] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "os.environ[\"GOOGLE_CSE_ID\"] = os.getenv(\"GOOGLE_CSE_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import Tool\n",
    "from langchain_google_community import GoogleSearchAPIWrapper\n",
    "\n",
    "search = GoogleSearchAPIWrapper()\n",
    "\n",
    "search_tool = Tool(\n",
    "    name='google_search',\n",
    "    description='Search google for recent results',\n",
    "    func=search.run,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GDG on Campus University of Embu - Embu, Kenya. Join us for an immersive Data ... Organizers. Alex Nyambura. Postman. Lead Organizer. See bio. Erick Mwangi. GDG On Campus University of Embu reposted this. View profile for Erick Mwangi. Erick Mwangi. GDGoC AI ML Lead || BLACKBOX.AI Maverick || Postman Student Expert. Oct 28, 2024 ... Google Developer Groups GDG on Campus University of Embu - Embu, Kenya presents Getting Started with Machine Learning ... Speaker. Erick\\xa0... Sep 17, 2021 ... GICHOHI, Mwangi Erick. 77. IKUNDA, Angela Makena. 78. JENNIFER, Kawira. 79. JOASH, Kiprop. 80. KAGEMA, Samuel Mbugua. 81. KAMAU, Gloria Mugure. Erick Githinji. Attended University of Embu. Nairobi County, Kenya. University of Embu ... Erick Mwangi Githinji. Student at college. Nairobi. college. LinkedIn\\xa0... University of Embu. Rapporteurs: Ms Mercy Wasonga and Ms Cecilia Mwende. Compiled by MS Irene Mwangi. Edited by Prof. Nancy Budambula. Date: 27th May 2021. Works at Self-Employed. Studied at Embu university main campus. Lives in Nairobi, Kenya. From Embu, Kenya. Thomas Mwangi. 15. Mr. Francis Migwi. 16. Mr. Erick Otieno. 17. Mr. Anyona ... students who graduated from the University of Embu had published their work\\xa0... Oct 1, 2024 ... ... Mwangi, Joseph Mugo, Malachi Okeyo, Vdj Smartix Ke, Nelson ... Chekai, a fourth-year English Literature student at the University of Embu\\xa0... ... University of Embu, P. O. Box 6, Code- 60100,. Embu Kenya. 2Department of Education, School of Education and Social Sciences, University of Embu, Kenya\\xa0...'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_tool.run(\"Erick Mwangi University of embu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'pdf_docs' ready\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x0000020566796680>, search_kwargs={})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The pdfloader\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.vectorstores import FAISS\n",
    "import chromadb\n",
    "\n",
    "os.makedirs(\"./chroma_db/pdf_data/cnet\", exist_ok=True)\n",
    "os.makedirs(\"./chroma_db/pdf_data/dbms\", exist_ok=True)\n",
    "os.makedirs(\"./chroma_db/pdf_data/edp\", exist_ok=True)\n",
    "os.makedirs(\"./chroma_db/pdf_data/mis\", exist_ok=True)\n",
    "os.makedirs(\"./chroma_db/pdf_data/open_source\", exist_ok=True)\n",
    "os.makedirs(\"./chroma_db/pdf_data/research\", exist_ok=True)\n",
    "os.makedirs(\"./chroma_db/pdf_data/swe\", exist_ok=True)\n",
    "\n",
    "loader = PyPDFDirectoryLoader(path='./cnet/')\n",
    "\n",
    "data = loader.load()\n",
    "splitted_docs = RecursiveCharacterTextSplitter(chunk_size=1000,\n",
    "                                               chunk_overlap=200).split_documents(data)\n",
    "# Create ChromaDB client for PDF data\n",
    "pdf_client = chromadb.PersistentClient(path=\"./chroma_db/pdf_data/cnet\")\n",
    "\n",
    "# Create the collection\n",
    "try:\n",
    "    collection = pdf_client.get_or_create_collection(\"cnet_docs\")\n",
    "    print(f\"Collection 'pdf_docs' ready\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating collection: {e}\")\n",
    "\n",
    "# Create Chroma vector store for PDF documents\n",
    "pdf_db = Chroma(\n",
    "    client=pdf_client,\n",
    "    collection_name=\"cnet_docs\",\n",
    "    embedding_function=GoogleGenerativeAIEmbeddings(model='models/text-embedding-004'),\n",
    ")\n",
    "\n",
    "# Add documents\n",
    "pdf_db.add_documents(splitted_docs)\n",
    "\n",
    "\n",
    "cnet_retreiver = pdf_db.as_retriever()\n",
    "cnet_retreiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'pdf_docs' ready\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x0000020566ABAF20>, search_kwargs={})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = PyPDFDirectoryLoader(path='./cnet/')\n",
    "\n",
    "data = loader.load()\n",
    "splitted_docs = RecursiveCharacterTextSplitter(chunk_size=1000,\n",
    "                                               chunk_overlap=200).split_documents(data)\n",
    "# Create ChromaDB client for PDF data\n",
    "pdf_client = chromadb.PersistentClient(path=\"./chroma_db/pdf_data/cnet\")\n",
    "\n",
    "# Create the collection\n",
    "try:\n",
    "    collection = pdf_client.get_or_create_collection(\"cnet_docs\")\n",
    "    print(f\"Collection 'pdf_docs' ready\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating collection: {e}\")\n",
    "\n",
    "# Create Chroma vector store for PDF documents\n",
    "pdf_db = Chroma(\n",
    "    client=pdf_client,\n",
    "    collection_name=\"cnet_docs\",\n",
    "    embedding_function=GoogleGenerativeAIEmbeddings(model='models/text-embedding-004'),\n",
    ")\n",
    "\n",
    "# Add documents\n",
    "pdf_db.add_documents(splitted_docs)\n",
    "\n",
    "\n",
    "cnet_retreiver = pdf_db.as_retriever()\n",
    "cnet_retreiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'pdf_docs' ready\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x0000020566A37430>, search_kwargs={})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = PyPDFDirectoryLoader(path='./edp/')\n",
    "\n",
    "data = loader.load()\n",
    "splitted_docs = RecursiveCharacterTextSplitter(chunk_size=1000,\n",
    "                                               chunk_overlap=200).split_documents(data)\n",
    "# Create ChromaDB client for PDF data\n",
    "pdf_client = chromadb.PersistentClient(path=\"./chroma_db/pdf_data/edp\")\n",
    "\n",
    "# Create the collection\n",
    "try:\n",
    "    collection = pdf_client.get_or_create_collection(\"edp_docs\")\n",
    "    print(f\"Collection 'pdf_docs' ready\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating collection: {e}\")\n",
    "\n",
    "# Create Chroma vector store for PDF documents\n",
    "pdf_db = Chroma(\n",
    "    client=pdf_client,\n",
    "    collection_name=\"edp_docs\",\n",
    "    embedding_function=GoogleGenerativeAIEmbeddings(model='models/text-embedding-004'),\n",
    ")\n",
    "\n",
    "# Add documents\n",
    "pdf_db.add_documents(splitted_docs)\n",
    "\n",
    "\n",
    "edp_retreiver = pdf_db.as_retriever()\n",
    "edp_retreiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'pdf_docs' ready\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x00000205654C1540>, search_kwargs={})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = PyPDFDirectoryLoader(path='./mis/')\n",
    "\n",
    "data = loader.load()\n",
    "splitted_docs = RecursiveCharacterTextSplitter(chunk_size=1000,\n",
    "                                               chunk_overlap=200).split_documents(data)\n",
    "# Create ChromaDB client for PDF data\n",
    "pdf_client = chromadb.PersistentClient(path=\"./chroma_db/pdf_data/mis\")\n",
    "\n",
    "# Create the collection\n",
    "try:\n",
    "    collection = pdf_client.get_or_create_collection(\"mis_docs\")\n",
    "    print(f\"Collection 'pdf_docs' ready\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating collection: {e}\")\n",
    "\n",
    "# Create Chroma vector store for PDF documents\n",
    "pdf_db = Chroma(\n",
    "    client=pdf_client,\n",
    "    collection_name=\"mis_docs\",\n",
    "    embedding_function=GoogleGenerativeAIEmbeddings(model='models/text-embedding-004'),\n",
    ")\n",
    "\n",
    "# Add documents\n",
    "pdf_db.add_documents(splitted_docs)\n",
    "\n",
    "\n",
    "mis_retreiver = pdf_db.as_retriever()\n",
    "mis_retreiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'pdf_docs' ready\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x0000020566797250>, search_kwargs={})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = PyPDFDirectoryLoader(path='./open_source/')\n",
    "\n",
    "data = loader.load()\n",
    "splitted_docs = RecursiveCharacterTextSplitter(chunk_size=1000,\n",
    "                                               chunk_overlap=200).split_documents(data)\n",
    "# Create ChromaDB client for PDF data\n",
    "pdf_client = chromadb.PersistentClient(path=\"./chroma_db/pdf_data/open_source\")\n",
    "\n",
    "# Create the collection\n",
    "try:\n",
    "    collection = pdf_client.get_or_create_collection(\"open_source_docs\")\n",
    "    print(f\"Collection 'pdf_docs' ready\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating collection: {e}\")\n",
    "\n",
    "# Create Chroma vector store for PDF documents\n",
    "pdf_db = Chroma(\n",
    "    client=pdf_client,\n",
    "    collection_name=\"open_source_docs\",\n",
    "    embedding_function=GoogleGenerativeAIEmbeddings(model='models/text-embedding-004'),\n",
    ")\n",
    "\n",
    "# Add documents\n",
    "pdf_db.add_documents(splitted_docs)\n",
    "\n",
    "\n",
    "open_source_retreiver = pdf_db.as_retriever()\n",
    "open_source_retreiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'pdf_docs' ready\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x0000020565454F70>, search_kwargs={})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = PyPDFDirectoryLoader(path='./research/')\n",
    "\n",
    "data = loader.load()\n",
    "splitted_docs = RecursiveCharacterTextSplitter(chunk_size=1000,\n",
    "                                               chunk_overlap=200).split_documents(data)\n",
    "# Create ChromaDB client for PDF data\n",
    "pdf_client = chromadb.PersistentClient(path=\"./chroma_db/pdf_data/research\")\n",
    "\n",
    "# Create the collection\n",
    "try:\n",
    "    collection = pdf_client.get_or_create_collection(\"research_docs\")\n",
    "    print(f\"Collection 'pdf_docs' ready\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating collection: {e}\")\n",
    "\n",
    "# Create Chroma vector store for PDF documents\n",
    "pdf_db = Chroma(\n",
    "    client=pdf_client,\n",
    "    collection_name=\"research_docs\",\n",
    "    embedding_function=GoogleGenerativeAIEmbeddings(model='models/text-embedding-004'),\n",
    ")\n",
    "\n",
    "# Add documents\n",
    "pdf_db.add_documents(splitted_docs)\n",
    "\n",
    "\n",
    "research_retreiver = pdf_db.as_retriever()\n",
    "research_retreiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'pdf_docs' ready\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x00000205654C3A00>, search_kwargs={})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = PyPDFDirectoryLoader(path='./swe/')\n",
    "\n",
    "data = loader.load()\n",
    "splitted_docs = RecursiveCharacterTextSplitter(chunk_size=1000,\n",
    "                                               chunk_overlap=200).split_documents(data)\n",
    "# Create ChromaDB client for PDF data\n",
    "pdf_client = chromadb.PersistentClient(path=\"./chroma_db/pdf_data/swe\")\n",
    "\n",
    "# Create the collection\n",
    "try:\n",
    "    collection = pdf_client.get_or_create_collection(\"swe_docs\")\n",
    "    print(f\"Collection 'pdf_docs' ready\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating collection: {e}\")\n",
    "\n",
    "# Create Chroma vector store for PDF documents\n",
    "pdf_db = Chroma(\n",
    "    client=pdf_client,\n",
    "    collection_name=\"swe_docs\",\n",
    "    embedding_function=GoogleGenerativeAIEmbeddings(model='models/text-embedding-004'),\n",
    ")\n",
    "\n",
    "# Add documents\n",
    "pdf_db.add_documents(splitted_docs)\n",
    "\n",
    "\n",
    "swe_retreiver = pdf_db.as_retriever()\n",
    "swe_retreiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'pdf_docs' ready\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x0000020563C92F50>, search_kwargs={})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = PyPDFDirectoryLoader(path='./dbms/')\n",
    "\n",
    "data = loader.load()\n",
    "splitted_docs = RecursiveCharacterTextSplitter(chunk_size=1000,\n",
    "                                               chunk_overlap=200).split_documents(data)\n",
    "# Create ChromaDB client for PDF data\n",
    "pdf_client = chromadb.PersistentClient(path=\"./chroma_db/pdf_data/dbms\")\n",
    "\n",
    "# Create the collection\n",
    "try:\n",
    "    collection = pdf_client.get_or_create_collection(\"dbms_docs\")\n",
    "    print(f\"Collection 'pdf_docs' ready\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating collection: {e}\")\n",
    "\n",
    "# Create Chroma vector store for PDF documents\n",
    "pdf_db = Chroma(\n",
    "    client=pdf_client,\n",
    "    collection_name=\"dbms_docs\",\n",
    "    embedding_function=GoogleGenerativeAIEmbeddings(model='models/text-embedding-004'),\n",
    ")\n",
    "\n",
    "# Add documents\n",
    "pdf_db.add_documents(splitted_docs)\n",
    "\n",
    "\n",
    "dbms_retreiver = pdf_db.as_retriever()\n",
    "dbms_retreiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[VectorStoreRetriever(tags=['Chroma', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x0000020566ABAF20>, search_kwargs={}),\n",
       " VectorStoreRetriever(tags=['Chroma', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x0000020563C92F50>, search_kwargs={}),\n",
       " VectorStoreRetriever(tags=['Chroma', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x0000020566A37430>, search_kwargs={}),\n",
       " VectorStoreRetriever(tags=['Chroma', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x00000205654C1540>, search_kwargs={}),\n",
       " VectorStoreRetriever(tags=['Chroma', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x0000020566797250>, search_kwargs={}),\n",
       " VectorStoreRetriever(tags=['Chroma', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x0000020565454F70>, search_kwargs={}),\n",
       " VectorStoreRetriever(tags=['Chroma', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x00000205654C3A00>, search_kwargs={})]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_retreivers = [cnet_retreiver, dbms_retreiver, edp_retreiver, mis_retreiver, open_source_retreiver, research_retreiver, swe_retreiver]\n",
    "pdf_retreivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"https://e-learning.embuni.ac.ke/course/view.php?id=14313\", IMS\n",
    "# \"https://e-learning.embuni.ac.ke/course/view.php?id=14315\", DBMS\n",
    "# \"https://e-learning.embuni.ac.ke/course/view.php?id=14291\", SWE\n",
    "# \"https://e-learning.embuni.ac.ke/course/view.php?id=14312\", EDP\n",
    "# \"https://e-learning.embuni.ac.ke/course/view.php?id=14316\", research\n",
    "# \"https://e-learning.embuni.ac.ke/course/view.php?id=12075\", cnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='5120e23c-16f4-43c8-b62c-731f90d96287', metadata={'author': 'Admin', 'creationdate': '2025-03-23T13:22:55+03:00', 'creator': 'Microsoft® Word LTSC', 'moddate': '2025-03-23T13:22:55+03:00', 'page': 4, 'page_label': '5', 'producer': 'Microsoft® Word LTSC', 'source': 'dbms\\\\TOPIC 3.pdf', 'total_pages': 7}, page_content='the most frequently used programming language in the world, in the sense that \\nevery day, more SQL programs are written, compiled and executed than programs \\nin any other computer programming language. SQL is used with relational database \\nsystems. In a relational database, all of the data is stored in tables.'),\n",
       " Document(id='46e6689b-0245-4fb1-80aa-a592103d2268', metadata={'author': 'Admin', 'creationdate': '2025-03-23T13:21:26+03:00', 'creator': 'Microsoft® Word LTSC', 'moddate': '2025-03-23T13:21:26+03:00', 'page': 0, 'page_label': '1', 'producer': 'Microsoft® Word LTSC', 'source': 'dbms\\\\TOPIC 1.pdf', 'total_pages': 11}, page_content=\"1.0  Introduction  \\n  \\nStructured Query Language (SQL) is a database computer language designed for \\nmanaging data in relational database management systems (RDBMS). Its scope \\nincludes data query and update, schema creation and modification, and data access \\ncontrol.  \\n  \\nSQL was developed at IBM by Andrew Richardson, Donald C. Messerly and \\nRaymond F. Boyce in the early 1970s. This version, initially called SEQUEL, was \\ndesigned to manipulate and retrieve data stored in IBM's original relational \\ndatabase product, System R.  \\n  \\nSQL has two major parts:  \\n  \\na. Data Definition Language (DDL) Used to create (define) data structures such \\nas tables, indexes, clusters  \\nb. Data Manipulation Language (DML) is used to store, retrieve and update \\ndata from tables.  \\n  \\n2.0  Objectives  \\n  \\nBy the end of this unit, you should be able to:  \\n  \\nn. Know what relational algebra is all about  \\n  \\n  \\n3.0  What Can SQL do?  \\n  \\na. SQL can execute queries against a database\"),\n",
       " Document(id='d0d75be0-670b-4b54-87d6-a197408128f9', metadata={'author': 'Admin', 'creationdate': '2025-03-23T13:22:55+03:00', 'creator': 'Microsoft® Word LTSC', 'moddate': '2025-03-23T13:22:55+03:00', 'page': 5, 'page_label': '6', 'producer': 'Microsoft® Word LTSC', 'source': 'dbms\\\\TOPIC 3.pdf', 'total_pages': 7}, page_content='5.0  Summary  \\n In this unit, we have \\nlearnt:  \\n  \\nxxix. Structured Query Language (SQL) is a database computer language \\ndesigned for managing data in relational database management systems \\n(RDBMS).  \\nxxx. SQL has two major parts: Data Definition Language and Data Manipulation \\nLanguage.  \\nxxxi. Data Definition Language (DDL) Used to create (define) data structures \\nsuch as tables, indexes, clusters xxxii. Some of the available DDL \\ncommands are: Create, Use, Alter, and Drop  \\nxxxiii.  SQL Constraints are used to limit the type of data that can go into a table. The \\nfollowing constraint types were considered: Not Null, Unique, Primary Key,  \\nForeign Key xxxiv. Data Manipulation Language (DML) is used to \\nmanipulate (select, insert, update, delete) data in a Table.  \\nxxxv.  The JOIN keyword is used in an SQL statement to query data from two \\nor more tables, based on a relationship between certain columns in these tables.'),\n",
       " Document(id='ce4cf070-8e0c-47f1-980d-5cf128b3d585', metadata={'author': 'Admin', 'creationdate': '2025-03-23T13:23:53+03:00', 'creator': 'Microsoft® Word LTSC', 'moddate': '2025-03-23T13:23:53+03:00', 'page': 18, 'page_label': '19', 'producer': 'Microsoft® Word LTSC', 'source': 'dbms\\\\TOPIC 5.pdf', 'total_pages': 26}, page_content='b. Confidentiality and Accountability through Authorization rules  \\nc. Encrypt ion  \\nd. Authentication Scheme  \\na. Operating system Availability:  The operating system should verify that \\nusers \\nand application programs attempting to access the system are authorized.')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_db.similarity_search('What is linux')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert this retreiver into a tool\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "cnet = create_retriever_tool(\n",
    "    retriever=cnet_retreiver,\n",
    "    name='cnet retreiver',\n",
    "    description='Get educational content about computer networks'\n",
    ")\n",
    "dbms = create_retriever_tool(\n",
    "    retriever=dbms_retreiver,\n",
    "    name='dbms retreiver',\n",
    "    description='Get educational content about database management systems'\n",
    ")\n",
    "edp = create_retriever_tool(\n",
    "    retriever=edp_retreiver,\n",
    "    name='edp retreiver',\n",
    "    description='Get educational content about event driven programming'\n",
    ")\n",
    "mis = create_retriever_tool(\n",
    "    retriever=mis_retreiver,\n",
    "    name='mis retreiver',\n",
    "    description='Get educational content about information management systems'\n",
    ")\n",
    "open_source = create_retriever_tool(\n",
    "    retriever=open_source_retreiver,\n",
    "    name='open source retreiver',\n",
    "    description='Get educational content about open source applications'\n",
    ")\n",
    "research = create_retriever_tool(\n",
    "    retriever=research_retreiver,\n",
    "    name='research retreiver',\n",
    "    description='Get educational content about research methods'\n",
    ")\n",
    "swe = create_retriever_tool(\n",
    "    retriever=swe_retreiver,\n",
    "    name='swe retreiver',\n",
    "    description='Get educational content about software engineering'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'swe retreiver'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swe.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login successful!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Set up the session\n",
    "session = requests.Session()\n",
    "\n",
    "# 1. Get login token (if needed)\n",
    "login_page_url = \"https://e-learning.embuni.ac.ke/login/index.php\"\n",
    "login_page = session.get(login_page_url)\n",
    "soup = BeautifulSoup(login_page.text, \"html.parser\")\n",
    "login_token = soup.find(\"input\", {\"name\": \"logintoken\"})[\"value\"]\n",
    "\n",
    "# 2. Send login POST request\n",
    "login_url = \"https://e-learning.embuni.ac.ke/login/index.php\"\n",
    "payload = {\n",
    "    \"username\": \"rickmwas_official\",\n",
    "    \"password\": \"Platnumz9999!\",\n",
    "    \"logintoken\": login_token  # Include this only if required\n",
    "}\n",
    "\n",
    "response = session.post(login_url, data=payload)\n",
    "\n",
    "if \"Invalid login\" in response.text:\n",
    "    print(\"Login failed.\")\n",
    "else:\n",
    "    print(\"Login successful!\")\n",
    "\n",
    "\n",
    "urls = [\"https://e-learning.embuni.ac.ke/course/view.php?id=14313\",\n",
    "        \"https://e-learning.embuni.ac.ke/course/view.php?id=14315\",\n",
    "        \"https://e-learning.embuni.ac.ke/course/view.php?id=14291\",\n",
    "        \"https://e-learning.embuni.ac.ke/course/view.php?id=14312\",\n",
    "        \"https://e-learning.embuni.ac.ke/course/view.php?id=14316\",\n",
    "        \"https://e-learning.embuni.ac.ke/course/view.php?id=12075\",\n",
    "        \"https://e-learning.embuni.ac.ke/course/view.php?id=14314\"]\n",
    "\n",
    "contents = []\n",
    "for url in urls:\n",
    "    page = session.get(url)\n",
    "    if page.status_code == 200:\n",
    "        contents.append(page.text)\n",
    "    else:\n",
    "        print(f\"Failed to access {url}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"./chroma_db/web_data\", exist_ok=True)\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "docs = [Document(page_content=html) for html in contents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'web_docs' ready\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x0000020563C935B0>, search_kwargs={})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitted_web_docs = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200).split_documents(docs)\n",
    "# Create ChromaDB client for web data\n",
    "web_client = chromadb.PersistentClient(path=\"./chroma_db/web_data\")\n",
    "\n",
    "# Create the collection\n",
    "try:\n",
    "    web_collection = web_client.get_or_create_collection(\"web_docs\")\n",
    "    print(f\"Collection 'web_docs' ready\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating collection: {e}\")\n",
    "\n",
    "# Create Chroma vector store for web documents\n",
    "web_db = Chroma(\n",
    "    client=web_client,\n",
    "    collection_name=\"web_docs\",\n",
    "    embedding_function=GoogleGenerativeAIEmbeddings(model='models/text-embedding-004'),\n",
    ")\n",
    "\n",
    "# Add documents\n",
    "web_db.add_documents(splitted_web_docs)\n",
    "\n",
    "\n",
    "web_retriever = web_db.as_retriever()\n",
    "web_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tool(name='web_retriever', description='Get Unit purpose and description, lecturer name etc..', func=<function search_embuni at 0x000002056698CF70>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the retriever tool\n",
    "def search_embuni(query):\n",
    "    \"\"\"Retrieve relevant content from the Embuni e-learning platform.\"\"\"\n",
    "    docs = web_retriever.invoke(query)\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "web_tool = Tool(\n",
    "    func=search_embuni,\n",
    "    name='web_retriever',\n",
    "    description='Get Unit purpose and description, lecturer name etc..'\n",
    ")\n",
    "\n",
    "web_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tool(name='cnet retreiver', description='Get educational content about computer networks', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x000002055AE2D2D0>, retriever=VectorStoreRetriever(tags=['Chroma', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x0000020566ABAF20>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x000002055B1437F0>, retriever=VectorStoreRetriever(tags=['Chroma', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x0000020566ABAF20>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content')),\n",
       " Tool(name='dbms retreiver', description='Get educational content about database management systems', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x000002055AE2D2D0>, retriever=VectorStoreRetriever(tags=['Chroma', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x0000020563C92F50>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x000002055B1437F0>, retriever=VectorStoreRetriever(tags=['Chroma', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x0000020563C92F50>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content')),\n",
       " Tool(name='edp retreiver', description='Get educational content about event driven programming', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x000002055AE2D2D0>, retriever=VectorStoreRetriever(tags=['Chroma', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x0000020566A37430>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x000002055B1437F0>, retriever=VectorStoreRetriever(tags=['Chroma', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x0000020566A37430>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content')),\n",
       " Tool(name='mis retreiver', description='Get educational content about information management systems', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x000002055AE2D2D0>, retriever=VectorStoreRetriever(tags=['Chroma', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x00000205654C1540>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x000002055B1437F0>, retriever=VectorStoreRetriever(tags=['Chroma', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x00000205654C1540>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content')),\n",
       " Tool(name='open source retreiver', description='Get educational content about open source applications', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x000002055AE2D2D0>, retriever=VectorStoreRetriever(tags=['Chroma', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x0000020566797250>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x000002055B1437F0>, retriever=VectorStoreRetriever(tags=['Chroma', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x0000020566797250>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content')),\n",
       " Tool(name='research retreiver', description='Get educational content about research methods', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x000002055AE2D2D0>, retriever=VectorStoreRetriever(tags=['Chroma', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x0000020565454F70>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x000002055B1437F0>, retriever=VectorStoreRetriever(tags=['Chroma', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x0000020565454F70>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content')),\n",
       " Tool(name='swe retreiver', description='Get educational content about software engineering', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x000002055AE2D2D0>, retriever=VectorStoreRetriever(tags=['Chroma', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x00000205654C3A00>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x000002055B1437F0>, retriever=VectorStoreRetriever(tags=['Chroma', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x00000205654C3A00>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content')),\n",
       " Tool(name='google_search', description='Search google for recent results', func=<bound method GoogleSearchAPIWrapper.run of GoogleSearchAPIWrapper(search_engine=<googleapiclient.discovery.Resource object at 0x00000205632680D0>, google_api_key='AIzaSyCieIdz_ZmVCo6egrBP02d_SDyvhHtwtmA', google_cse_id='e37096f3bd7c7405d', k=10, siterestrict=False)>),\n",
       " Tool(name='web_retriever', description='Get Unit purpose and description, lecturer name etc..', func=<function search_embuni at 0x000002056698CF70>)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = [cnet,\n",
    "         dbms,\n",
    "         edp,\n",
    "         mis,\n",
    "         open_source,\n",
    "         research,\n",
    "         swe,\n",
    "         search_tool,\n",
    "         web_tool]\n",
    "\n",
    "tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create multi search query agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call prompts from langchain hub\n",
    "from langchain import hub\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Define a more structured prompt template\n",
    "prompt = PromptTemplate.from_template(\"\"\"You are University of Embu's expert educational assistant for second year units, focused on helping students learn effectively.\n",
    "You prioritize thorough understanding and clear explanations based on reliable course materials.\n",
    "\n",
    "The units are:\n",
    " - Open Source Applications, Computer Networks, Database management systems, event driven programming, information system management, open source applications, research methods and software engineering.\n",
    "You have access to the following tools:\n",
    "{tools}\n",
    "\n",
    "STRATEGY GUIDELINES:\n",
    "1. ALWAYS check course PDF materials FIRST - these contain the most relevant and authoritative information\n",
    "2. Only use web search or other tools when the PDFs don't contain sufficient information\n",
    "3. When explaining concepts, include relevant examples and relate to real-world applications\n",
    "4. Break down complex topics into manageable parts\n",
    "5. If multiple sources provide different perspectives, synthesize them and explain the variations\n",
    "6. You can use web search to add more information to the content available in the documents\n",
    "7. The second priority after pdfs is checking from the web based agent tool\n",
    "\n",
    "You must follow this exact format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: your reasoning about what to do next (be thorough in your thinking)\n",
    "Action: the tool name to use (must be one of: {tool_names})\n",
    "Action Input: the input to pass to the tool\n",
    "Observation: the result from the tool\n",
    "... (you can repeat the Thought/Action/Action Input/Observation steps multiple times)\n",
    "Thought: your final reasoning - synthesize what you've learned and organize your response\n",
    "Final Answer: your comprehensive educational response that includes:\n",
    "  - Clear explanation of concepts\n",
    "  - Examples when helpful\n",
    "  - Citations to course materials when applicable\n",
    "  - Summary of key points\n",
    "\n",
    "Begin! Remember to ALWAYS follow the format exactly and prioritize course PDF materials before using other tools.\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\n",
    "\"\"\")\n",
    "\n",
    "memory = ChatMessageHistory(session_id=\"test-session\")\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the agent - will choose a sequence of actions to take using the tools based on the query\n",
    "from langchain.agents import create_structured_chat_agent, create_react_agent\n",
    "\n",
    "agent = create_react_agent(\n",
    "    llm=llm,\n",
    "    tools=tools,\n",
    "    prompt=prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executor to execute the agent\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True\n",
    ")\n",
    "\n",
    "agent_with_chat_history = RunnableWithMessageHistory(\n",
    "    executor,\n",
    "    # This is needed because in most real world scenarios, a session id is needed\n",
    "    # It isn't really used here because we are using a simple in memory ChatMessageHistory\n",
    "    lambda session_id: memory,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to list the units that I can provide information on. These are listed in the initial prompt.\n",
      "Final Answer: I can provide information on the following units: Open Source Applications, Computer Networks, Database Management Systems, Event Driven Programming, Information System Management, Research Methods, and Software Engineering.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What units do you offer?',\n",
       " 'chat_history': [],\n",
       " 'output': 'I can provide information on the following units: Open Source Applications, Computer Networks, Database Management Systems, Event Driven Programming, Information System Management, Research Methods, and Software Engineering.'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_with_chat_history.invoke({'input': \"What units do you offer?\"},\n",
    "                               config={\"configurable\": {\"session_id\": \"<foo>\"}},)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'agent_with_chat_history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43magent_with_chat_history\u001b[49m\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGive me a history of linux\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m      2\u001b[0m                                config\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfigurable\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msession_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<foo>\u001b[39m\u001b[38;5;124m\"\u001b[39m}},)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'agent_with_chat_history' is not defined"
     ]
    }
   ],
   "source": [
    "agent_with_chat_history.invoke({'input': \"Give me a history of linux\"},\n",
    "                               config={\"configurable\": {\"session_id\": \"<foo>\"}},)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DocuMentor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
